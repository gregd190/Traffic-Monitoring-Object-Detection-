{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Analysis - Advanced Stop Line Compliance\n",
    "\n",
    "The following is a description of an application to process intersection video to assess non-compliance rates of 'Advanced Stop Lines, more commonly known as 'bike boxes'. It was created to assist with a study on the effect of education programs and police presence on compliance rates, although it could be easily adapted to be used as a compliance enforcement tool. The code itself is not provided, but an example of the analysed video is. \n",
    "\n",
    "### Traffic Rules:\n",
    "\n",
    "The traffic rules regarding Advance Stop Lines, in the region in which the study is to be performed, are as follows:\n",
    "    * A vehicle can cross the advance stop line when the light is green or amber.\n",
    "    * A vehicle that crosses the advance stop line on green or amber is permitted to remain in the box if unable to safely \n",
    "      pass through the intersection.\n",
    "    * A vehicle may not cross the advance stop line while the light is red. \n",
    "    * Bicycles are able to enter the bike box via the bike lane during any light state. \n",
    "    \n",
    "The second point means that not all vehicles stopped in the bike box while the light is red are non-compliant. An approach that can determine the light state when a vehicle enters the box is required. \n",
    "\n",
    "### Approach:\n",
    "\n",
    "The goal is to simply to count the number of non-compliance events, and record where in the video they occur to allow human review. \n",
    "\n",
    "The best approach was deemed to be to analyse video post-capture. This allows a small, inexpensive camera to be installed discreetly at an intersection. \n",
    "\n",
    "##### Detecting Traffic Light State\n",
    "\n",
    "While it is relatively trivial to detect traffic lights in an image ('traffic light' is one of the categories in several of the  freely available pretrained object detection algorithms) there are often several traffic lights in frame, some of which may not be relevant to the intersection under study. The user is therefore asked to locate the traffic light by drawing a rectangle enclosing it. \n",
    "\n",
    "For each frame of the video analysed, the subset of the image that is enclosed by the selected rectangle is then fed to a convolutional neural network to be classified as either 'Red' or 'Not Red'. Note that the state with both red and amber lights illuminated is treated as 'not red'. \n",
    "\n",
    "##### Defining Detection Area/Stop Box:\n",
    "\n",
    "It is critical that the area bounded by the Advance Stop Line is well defined. While it is possible to detect the position of this box, it was unable to reliably define the relevant area. The user is therefore asked to draw a polygon bounding the relevant area (the 'detection area') when initially running the program.\n",
    "\n",
    "##### Detecting Vehicles in Image\n",
    "\n",
    "The pretrained YOLO-v3 multi-object detection system is applied to each frame. Irrelevant object classes (classes other than 'Car', 'Truck', 'Bus') are ignored. Relevant classes are bounded, and the location data (A central point, as well as height and width) recorded. Each box also has one or more 'detection points' defined. These are points for which the vehicle will be deemed to have crossed the Advance Stop Line once one or more detection points are in the detection area. The detection points are easily adaptable as they may need to be modified for optimal performance at different camera angles. The detection points are indicated on the image as small purple circles.  \n",
    "\n",
    "##### Detecting  Vehicles in Detection Area\n",
    "\n",
    "For each vehicle bounding box in the image, OpenCV's built-in point test functionality is used to determine whether one or more of the detection points are inside the detection area. If one or more detection points of an object are found to be inside the box, the vehicle is deemed to be within the box. The total number of vehicles detected in the box is summed. \n",
    "\n",
    "##### Determining Non-Compliances\n",
    "\n",
    "A non-compliance occurs when a vehicle enters the detection area while the traffic light state is red. Thus a non-compliance is recorded whenever ALL the following set of conditions is met:\n",
    "    1. The current frame traffic light state is red.\n",
    "    2. The previous frame traffic light state is red.\n",
    "    3. The number of vehicles detected in the detection area in the current frame is greater than in the previous frame. \n",
    "    \n",
    "##### Practical Considerations\n",
    "\n",
    "Due to the time taken to process each frame, only every 10th frame is assessed. At 30 fps, this equates to 3 frame samples per second. \n",
    "\n",
    "If higher performance was required, a few approaches could be considered:\n",
    "* Preprocessing the video file to determine the frame number ranges where red lights occur, and only applying the object detection to those frames.\n",
    "* Use of a faster (but potentially less accurate) object detection algorithm. \n",
    "\n",
    "### Demonstration\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"outpu.avi\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"outpu.avi\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
